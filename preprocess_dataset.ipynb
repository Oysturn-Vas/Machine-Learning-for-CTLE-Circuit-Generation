{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fec245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def combine_csv_files(folder_path, output_file_name):\n",
    "    \"\"\"\n",
    "    Combines data from multiple CSV files in a specified folder into one.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the CSV files.\n",
    "        output_file_name (str): The name of the new CSV file to save the combined data to.\n",
    "    \"\"\"\n",
    "    all_data = (\n",
    "        pd.DataFrame()\n",
    "    )  # Initialize an empty DataFrame to store all combined data\n",
    "\n",
    "    # Iterate through all files in the specified folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            try:\n",
    "                # Read the CSV file\n",
    "                # You might need to specify encoding if you encounter errors (e.g., encoding='utf-8')\n",
    "                df = pd.read_csv(file_path)\n",
    "                all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not read '{filename}': {e}\")\n",
    "\n",
    "    if not all_data.empty:\n",
    "        # Save the combined data to a new CSV file\n",
    "        # You might want to specify encoding here too (e.g., encoding='utf-8')\n",
    "        output_file_path = os.path.join(os.path.dirname(folder_path), output_file_name)\n",
    "        all_data.to_csv(output_file_path, index=False)\n",
    "        print(f\"\\nSuccessfully combined data into: {output_file_path}\")\n",
    "    else:\n",
    "        print(\"\\nNo data was combined. Please check folder path and file types (.csv).\")\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# IMPORTANT: Replace 'path/to/your/csv_files' with the actual path to your folder\n",
    "csv_files_folder = r\"C:\\Users\\oystu\\Desktop\\Waterloo\\2. Spring 2025\\ECE 720 - ML for Chip Design\\Project\\Project\\Dataset\"  # Example: r\"C:\\Users\\YourName\\Documents\\my_csv_files\" or \"/Users/YourName/Documents/my_csv_files\"\n",
    "output_csv_name = \"Combined_ProcessedData.csv\"\n",
    "\n",
    "# Run the function\n",
    "combine_csv_files(csv_files_folder, output_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def combine_all_rates_for_each_region(folder_path, output_filename):\n",
    "    \"\"\"\n",
    "    Finds sets of 7G, 14G, 28G, and 56G files, merges their unique\n",
    "    columns for each set, and then combines all sets into a single output file.\n",
    "    \"\"\"\n",
    "    print(f\"Searching for base files (7G) in: {folder_path}\")\n",
    "\n",
    "    try:\n",
    "        all_filenames = os.listdir(folder_path)\n",
    "        base_filenames_7g = [f for f in all_filenames if f.endswith(\"_7G_input.0.csv\")]\n",
    "        base_files_7g = [os.path.join(folder_path, f) for f in base_filenames_7g]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The specified folder was not found -> {folder_path}\")\n",
    "        return\n",
    "\n",
    "    if not base_files_7g:\n",
    "        print(\n",
    "            \"No '..._7G_input.0' files found. Please check the folder path and filenames.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(base_files_7g)} sets to process.\")\n",
    "\n",
    "    list_of_all_processed_dfs = []\n",
    "\n",
    "    for file_7g_path in base_files_7g:\n",
    "        set_name = os.path.basename(file_7g_path).split(\"_region_\")[0]\n",
    "        print(f\"\\nProcessing set: {set_name}\")\n",
    "\n",
    "        try:\n",
    "            print(f\"  -> Reading base file: {os.path.basename(file_7g_path)}\")\n",
    "            # MODIFICATION: Removed sep=r'\\s+' to read as a standard CSV\n",
    "            combined_df = pd.read_csv(file_7g_path)\n",
    "\n",
    "            rates_to_merge = [\"14G\", \"28G\", \"56G\"]\n",
    "\n",
    "            for rate in rates_to_merge:\n",
    "                next_file_path = file_7g_path.replace(\"_7G_input.0\", f\"_{rate}_input.0\")\n",
    "                if not os.path.exists(next_file_path):\n",
    "                    print(\n",
    "                        f\"  -> Warning: {os.path.basename(next_file_path)} not found. Skipping.\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                print(f\"  -> Merging columns from: {os.path.basename(next_file_path)}\")\n",
    "                # MODIFICATION: Removed sep=r'\\s+' to read as a standard CSV\n",
    "                next_df = pd.read_csv(next_file_path)\n",
    "\n",
    "                if len(next_df) != len(combined_df):\n",
    "                    print(\n",
    "                        \"  -> ❌ Error: Row count mismatch between files. Aborting this set.\"\n",
    "                    )\n",
    "                    combined_df = None\n",
    "                    break\n",
    "\n",
    "                unique_cols = list(set(next_df.columns) - set(combined_df.columns))\n",
    "                if unique_cols:\n",
    "                    print(f\"    -> Adding {len(unique_cols)} new unique columns.\")\n",
    "                    combined_df = pd.concat([combined_df, next_df[unique_cols]], axis=1)\n",
    "                else:\n",
    "                    print(\"    -> No new unique columns found.\")\n",
    "\n",
    "            if combined_df is not None:\n",
    "                list_of_all_processed_dfs.append(combined_df)\n",
    "                print(\n",
    "                    f\"  -> ✅ Set '{set_name}' processed and added to the final combination.\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"  -> ❌ An unexpected error occurred while processing set '{set_name}': {e}\"\n",
    "            )\n",
    "\n",
    "    if not list_of_all_processed_dfs:\n",
    "        print(\"\\nNo data was successfully processed to be combined.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nCombining data from all processed sets...\")\n",
    "    final_master_df = pd.concat(list_of_all_processed_dfs, ignore_index=True)\n",
    "\n",
    "    # Reorder columns to have parameters first, which are not present in this flow, but good practice\n",
    "    param_order = [\"fW\", \"current\", \"ind\", \"Rd\", \"Cs\", \"Rs\"]\n",
    "    existing_params = [p for p in param_order if p in final_master_df.columns]\n",
    "    other_cols = [c for c in final_master_df.columns if c not in existing_params]\n",
    "    final_master_df = final_master_df[existing_params + other_cols]\n",
    "\n",
    "    output_path = os.path.join(folder_path, output_filename)\n",
    "    final_master_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n✅✅✅ All data successfully combined into: {output_path}\")\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "data_folder = r\"C:\\Users\\oystu\\Desktop\\Waterloo\\2. Spring 2025\\ECE 720 - ML for Chip Design\\Project\\ECE720T32-Using-ML-for-CTLE-Circuit-Generation\\dv3\"\n",
    "final_output_name = \"DataCombined.csv\"\n",
    "\n",
    "# --- Run the Script ---\n",
    "combine_all_rates_for_each_region(data_folder, final_output_name)\n",
    "print(\"\\nProcess finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c84333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def combine_csv_files(folder_path, output_filename):\n",
    "    \"\"\"\n",
    "    Finds all CSV files starting with 'DataCombined' using os.listdir(),\n",
    "    and concatenates them into a single output file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- MODIFICATION START ---\n",
    "        # Use os.listdir() to get all filenames in the folder\n",
    "        all_filenames_in_dir = os.listdir(folder_path)\n",
    "\n",
    "        # Filter the list to find files that match our criteria\n",
    "        matching_filenames = [\n",
    "            f\n",
    "            for f in all_filenames_in_dir\n",
    "            if f.startswith(\"DataCombined\") and f.endswith(\".csv\")\n",
    "        ]\n",
    "\n",
    "        # Create the full path for each matching file\n",
    "        file_list = [os.path.join(folder_path, f) for f in matching_filenames]\n",
    "        # --- MODIFICATION END ---\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Error: The specified folder was not found -> {folder_path}\")\n",
    "        return\n",
    "\n",
    "    if not file_list:\n",
    "        print(\n",
    "            f\"⚠️ No files starting with 'DataCombined' and ending with '.csv' were found in the folder.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(file_list)} files to combine.\")\n",
    "\n",
    "    list_of_dataframes = []\n",
    "\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            print(f\"Reading: {os.path.basename(file_path)}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            list_of_dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"  -> ❌ Error reading file {os.path.basename(file_path)}: {e}\")\n",
    "\n",
    "    if not list_of_dataframes:\n",
    "        print(\"No data could be read. Aborting combination.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nCombining all data...\")\n",
    "    final_combined_df = pd.concat(list_of_dataframes, ignore_index=True)\n",
    "\n",
    "    output_path = os.path.join(folder_path, output_filename)\n",
    "    final_combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"\\n✅ Success! All files have been combined into '{output_filename}'.\")\n",
    "    print(f\"Total rows in new file: {len(final_combined_df)}\")\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# Please confirm this is the correct folder containing your 'DataCombined' files.\n",
    "data_folder = r\"C:\\Users\\oystu\\Desktop\\Waterloo\\2. Spring 2025\\ECE 720 - ML for Chip Design\\Project\\ECE720T32-Using-ML-for-CTLE-Circuit-Generation\\combinedData\"\n",
    "output_file = \"DataV2.csv\"\n",
    "\n",
    "# --- Run the Script ---\n",
    "combine_csv_files(data_folder, output_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
